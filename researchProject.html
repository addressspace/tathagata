<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Projects</title>
    <!-- Font Awesome for icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
    <!-- Fireflies effect -->
    <link rel="stylesheet" href="fireflies.css">
    <style id="fireflies-override">
        /* Override fireflies container to fix footer overflow */
        #fireflies-container {
            height: 100vh !important;
            max-height: 100vh !important;
            bottom: auto !important;
        }
    </style>
    <style>
        :root {
            --primary-color: #2563eb;
            --secondary-color: #4f46e5;
            --accent-color: #7c3aed;
            --text-color: #334155;
            --light-bg: #f8fafc;
            --border-color: rgba(255, 255, 255, 0.2);
            --glass-bg: rgba(255, 255, 255, 0.15);
            --glass-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.15);
            --glass-border: 1px solid rgba(255, 255, 255, 0.18);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        @keyframes gradientAnimation {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background: linear-gradient(-45deg, #f0f4f8, #e6f1ff, #edf2ff, #f5f7fa);
            background-size: 400% 400%;
            animation: gradientAnimation 15s ease infinite;
            padding: 0;
            margin: 0;
            background-attachment: fixed;
            position: relative;
            perspective: 1000px;
            overflow-x: hidden;
        }
        
        /* Create a 3D parallax container for background elements */
        #parallax-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100vh;
            z-index: -15;
            pointer-events: none;
            perspective: 1000px;
            perspective-origin: 50% 50%;
            transform-style: preserve-3d;
            overflow: hidden;
        }
        
        /* First layer of dots (middle distance) */
        #parallax-dots {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="100" height="100" viewBox="0 0 100 100"><circle cx="50" cy="50" r="1" fill="%23ffffff" opacity="0.3"/></svg>');
            background-size: 150px 150px;
            transform: translateZ(-300px) scale(1.3);
            opacity: 0.4;
            will-change: transform;
        }
        
        /* Second layer of dots (far distance) */
        #parallax-dots-deep {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="300" height="300" viewBox="0 0 300 300"><circle cx="150" cy="150" r="2" fill="%23ffffff" opacity="0.15"/></svg>');
            background-size: 300px 300px;
            transform: translateZ(-600px) scale(1.6);
            opacity: 0.3;
            will-change: transform;
        }

        header {
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--accent-color) 100%);
            color: white;
            text-align: center;
            padding: 3rem 1rem;
            margin-bottom: 2rem;
            position: relative;
            overflow: hidden;
            box-shadow: var(--glass-shadow);
        }

        header::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            z-index: 0;
        }

        header h1, header h2, header div {
            position: relative;
            z-index: 1;
        }

        header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            font-weight: 700;
            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        header h2 {
            font-size: 1.5rem;
            font-weight: normal;
            opacity: 0.9;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 1.5rem;
            position: relative;
            z-index: 5;
        }

        section {
            margin-bottom: 3rem;
        }

        h2 {
            color: var(--primary-color);
            margin-bottom: 1.5rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid var(--secondary-color);
            font-weight: 600;
        }

        .project {
            background: var(--glass-bg);
            backdrop-filter: blur(16px);
            -webkit-backdrop-filter: blur(16px);
            border-radius: 16px;
            box-shadow: var(--glass-shadow);
            border: var(--glass-border);
            margin-bottom: 3rem;
            overflow: hidden;
            transition: transform 0.5s ease, box-shadow 0.5s ease, opacity 0.8s ease;
            opacity: 0;
            transform: translateY(30px);
            will-change: transform; /* Optimize for animations */
            position: relative;
            z-index: 2;
        }

        .project-visible {
            opacity: 1;
            transform: translateY(0);
        }

        .project:hover {
            transform: translateY(-5px);
            box-shadow: 0 12px 40px rgba(31, 38, 135, 0.2);
        }

        .project-header {
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--accent-color) 100%);
            color: white;
            padding: 1.8rem;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .project-header::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(5px);
            -webkit-backdrop-filter: blur(5px);
            z-index: 0;
        }

        .project-header h2 {
            color: white;
            border-bottom: none;
            margin-bottom: 0.5rem;
            position: relative;
            z-index: 1;
            font-weight: 600;
        }

        .project-content {
            padding: 2.5rem;
            background: rgba(255, 255, 255, 0.7);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            position: relative;
            z-index: 1;
        }
        
        .project-content::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 1px;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.8), transparent);
            z-index: 2;
        }

        .authors {
            text-align: center;
            margin-bottom: 1.5rem;
        }

        .affiliations {
            font-style: italic;
            text-align: center;
            margin-bottom: 20px;
            color: #555;
            font-size: 0.9rem;
        }

        .project-description {
            margin-bottom: 2rem;
            text-align: justify;
            line-height: 1.8;
        }

        .publication-info {
            background: var(--glass-bg);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            border-radius: 12px;
            border: var(--glass-border);
            padding: 1.8rem;
            margin-bottom: 2.5rem;
            box-shadow: var(--glass-shadow);
            position: relative;
            overflow: hidden;
        }
        
        .publication-info::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
            opacity: 0.7;
            z-index: 0;
        }
        
        .publication-info h3, .publication-info p, .publication-info a {
            position: relative;
            z-index: 1;
        }

        .publication-info p {
            margin-bottom: 0.8rem;
        }

        .publication-info a {
            color: var(--secondary-color);
            text-decoration: none;
            transition: color 0.3s;
            font-weight: 500;
        }

        .publication-info a:hover {
            color: var(--accent-color);
            text-decoration: underline;
        }

        .figures-container {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(500px, 1fr));
            gap: 30px;
            margin-top: 2rem;
        }

        .figure-item {
            background: var(--glass-bg);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            border-radius: 12px;
            border: var(--glass-border);
            overflow: hidden;
            transition: transform 0.4s ease, box-shadow 0.4s ease;
            box-shadow: var(--glass-shadow);
            will-change: transform; /* Optimize for animations */
            position: relative;
            z-index: 1;
        }

        .figure-item:hover {
            transform: translateY(-8px) !important; /* Override parallax when hovering */
            box-shadow: 0 20px 40px rgba(31, 38, 135, 0.25);
        }

        .figure-item img {
            width: 100%;
            height: auto;
            display: block;
            object-fit: contain;
            border-bottom: var(--glass-border);
            transition: all 0.4s ease;
            filter: brightness(1.02) contrast(1.05);
        }
        
        .figure-item:hover img {
            filter: brightness(1.05) contrast(1.08);
        }

        .figure-caption {
            padding: 1.8rem;
            background: rgba(255, 255, 255, 0.7);
            backdrop-filter: blur(5px);
            -webkit-backdrop-filter: blur(5px);
        }

        .figure-caption h3 {
            color: var(--primary-color);
            margin-bottom: 0.8rem;
            font-size: 1.3rem;
            font-weight: 600;
        }

        .figure-caption p {
            font-size: 1.05rem;
            line-height: 1.6;
        }

        .introduction ul {
            padding-left: 2rem;
        }

        .introduction li {
            margin-bottom: 1rem;
            line-height: 1.7;
        }

        .references {
            background: var(--glass-bg);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            padding: 1.8rem;
            border-radius: 12px;
            margin-top: 2.5rem;
            border: var(--glass-border);
            box-shadow: var(--glass-shadow);
        }

        .references h3 {
            color: var(--primary-color);
            margin-bottom: 1.2rem;
            font-weight: 600;
        }

        .references ol {
            padding-left: 2rem;
        }

        .references li {
            margin-bottom: 1rem;
            font-size: 0.95rem;
            line-height: 1.7;
        }

        footer {
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--accent-color) 100%);
            color: white;
            text-align: center;
            padding: 2rem;
            font-size: 0.95rem;
            margin-top: 4rem;
            position: relative;
            overflow: hidden;
            width: 100%;
            box-sizing: border-box;
            z-index: 10;
        }

        footer::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            z-index: 0;
        }

        footer .container {
            position: relative;
            z-index: 1;
            width: 100%;
            max-width: 1200px;
            margin: 0 auto;
        }

        .back-to-top {
            position: fixed;
            bottom: 30px;
            right: 30px;
            background: var(--glass-bg);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            color: var(--primary-color);
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
            text-decoration: none;
            opacity: 0;
            transition: all 0.3s ease;
            box-shadow: var(--glass-shadow);
            border: var(--glass-border);
            font-size: 1.2rem;
            font-weight: bold;
            z-index: 100;
        }

        .back-to-top.visible {
            opacity: 1;
        }

        .back-to-top:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(31, 38, 135, 0.3);
        }

        .project-divider {
            height: 2px;
            background: linear-gradient(to right, transparent, var(--secondary-color), transparent);
            margin: 4rem 0;
            opacity: 0.6;
        }

        .table-of-contents {
            background: var(--glass-bg);
            backdrop-filter: blur(16px);
            -webkit-backdrop-filter: blur(16px);
            padding: 2rem;
            border-radius: 16px;
            box-shadow: var(--glass-shadow);
            margin-bottom: 3rem;
            border: var(--glass-border);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .table-of-contents:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 35px rgba(31, 38, 135, 0.2);
        }

        .table-of-contents h3 {
            color: var(--primary-color);
            margin-bottom: 1.5rem;
            font-weight: 600;
            text-align: center;
        }

        .table-of-contents ul {
            list-style-type: none;
        }

        .table-of-contents li {
            margin-bottom: 1rem;
            position: relative;
            padding-left: 1.5rem;
        }

        .table-of-contents li::before {
            content: '→';
            position: absolute;
            left: 0;
            color: var(--accent-color);
        }

        .table-of-contents a {
            color: var(--secondary-color);
            text-decoration: none;
            font-weight: 500;
            transition: all 0.3s;
            padding: 0.3rem 0.5rem;
            border-radius: 4px;
            display: inline-block;
        }

        .table-of-contents a:hover {
            color: var(--accent-color);
            background: rgba(255, 255, 255, 0.5);
            transform: translateX(5px);
        }

        .home-link {
            color: white !important;
            text-decoration: none;
            background: rgba(255, 255, 255, 0.2) !important;
            padding: 10px 20px !important;
            border-radius: 30px !important;
            display: inline-block;
            transition: all 0.3s ease;
            backdrop-filter: blur(5px);
            -webkit-backdrop-filter: blur(5px);
            border: 1px solid rgba(255, 255, 255, 0.18);
            box-shadow: 0 8px 32px rgba(31, 38, 135, 0.2);
            font-weight: 500;
        }

        .home-link:hover {
            background: rgba(255, 255, 255, 0.3) !important;
            transform: translateY(-3px);
            box-shadow: 0 10px 25px rgba(31, 38, 135, 0.3);
        }

        h3 {
            color: var(--primary-color);
            margin: 1.5rem 0 1rem;
            font-weight: 600;
        }

        /* Responsive adjustments */
        @media (max-width: 992px) {
            .figures-container {
                grid-template-columns: repeat(auto-fill, minmax(400px, 1fr));
            }
        }

        /* Parallax fireflies styling */
        .parallax-firefly {
            opacity: 0.8;
            filter: blur(3px);
            box-shadow: 0 0 20px 5px rgba(123, 104, 238, 0.9);
            animation: blink 6s ease-in-out infinite;
            transition: transform 0.1s linear;
        }
        
        @media (max-width: 768px) {
            header h1 {
                font-size: 1.8rem;
            }
            
            header h2 {
                font-size: 1.2rem;
            }
            
            .figures-container {
                grid-template-columns: 1fr;
            }

            .project-content {
                padding: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <div id="parallax-container">
        <div id="parallax-dots"></div>
        <div id="parallax-dots-deep"></div>
    </div>
    <div id="main-wrapper" style="position: relative; z-index: 5; min-height: 100vh; display: flex; flex-direction: column;">
        <header>
            <h1>Research Projects</h1>
            <div style="margin-top: 20px;">
                <a href="index.html" class="home-link">
                    <i class="fas fa-home"></i> Back to Home
                </a>
            </div>
        </header>

        <div class="container" style="flex: 1 0 auto;">
        <section class="table-of-contents">
            <h3>Research Projects</h3>
            <ul>
                <li><a href="#project1">Optimizing Photoacoustic Imaging: Deep Learning Techniques to Overcome Limited-View Problem</a></li>
                <li><a href="#project2">Beyond the lens: Transforming light sheet fluorescence microscopy through stochastic elegance and iterative image refinement</a></li>
                <li><a href="#project3">Deep Learning-Based Photoacoustic Image Reconstruction Using a Single-Element Low-Frequency PMUT</a></li>
            </ul>
        </section>

        <!-- Project 1: Photoacoustic Imaging with FAU-Net -->
        <section id="project1" class="project">
            <div class="project-header">
                <h2>Optimizing Photoacoustic Imaging: Deep Learning Techniques to Overcome Limited-View Problem</h2>
            </div>
            <div class="project-content">
                <div class="authors">
                    <p>Tathagata Das<sup>1</sup>, Arijit Paramanick<sup>1</sup>, Souradip Paul, and Mayanglambam Suheshkumar Singh<sup>*</sup></p>
                    <p class="affiliations">
                        Biomedical and Nano-bioscience Engineering Lab. (BnBEng.LAB), School of Physics (SoP), Indian Institute of Science Education and Research Thiruvananthapuram (IISER TVM), Kerala, India<br>
                        <sup>1</sup> Authors contribute equally. <sup>*</sup> Corresponding author: suhesh.kumar@iisertvm.ac.in
                    </p>
                </div>

                <div class="project-description">
                    <p>
                        This research focused on overcoming the limited-view problem in photoacoustic imaging through advanced deep learning techniques. 
                        Our approach utilized a fast adaptive U-Net (FAU-Net) architecture to significantly enhance image reconstruction quality while 
                        maintaining high frame rates (~3 Hz) using single-element ultrasound transducers. The methodology was validated through both 
                        numerical simulations and experimental studies on diverse samples including mouse brain and goat eyes.
                    </p>
                    <p>
                        Key contributions include addressing image distortion and under-sampling in photoacoustic imaging (PAI), improving image quality metrics 
                        (PSNR, SSIM, SNR), implementing a faster deep learning algorithm, and working with a custom photoacoustic tomography (PAT) setup 
                        integrated with ultrasound systems for real-time applications. We also applied acoustic resolution microscopy to ocular data analysis.
                    </p>
                </div>

                <div class="publication-info">
                    <h3>Publication Status</h3>
                    <p style="font-style: italic; text-align: center; font-weight: bold;">
                        Manuscript under preparation
                    </p>
                </div>

                <h3>Research Figures</h3>
                <div class="figures-container">
                    <div class="figure-item">
                        <img src="Pai_images/Figure_2.jpg" alt="Figure 2: Simulation Setup">
                        <div class="figure-caption">
                            <h3>Figure 2</h3>
                            <p>(a) Tomography numerical simulation setup with linear transducer and agar phantom. (b) Microscopy numerical simulation setup with focused single-element transducer.</p>
                        </div>
                    </div>
                    
                    <div class="figure-item">
                        <img src="Pai_images/Figure_3.jpg" alt="Figure 3: Experimental Setup">
                        <div class="figure-caption">
                            <h3>Figure 3</h3>
                            <p>(i) PAT system: (a) Photograph of home-built PAT imaging system. (b) Schematic diagram of experimental setup. (ii) PAM system: (a) Photograph of AR-PAM imaging system. (b) Schematic diagram of experimental setup.</p>
                        </div>
                    </div>
                    
                    <div class="figure-item">
                        <img src="Pai_images/Figure_4.jpg" alt="Figure 4: PAT Image Comparison">
                        <div class="figure-caption">
                            <h3>Figure 4</h3>
                            <p>Reconstructed PAT images using conventional DAS, U-Net, HDU-Net, and FAU-Net, with SSIM and PSNR quantitative comparisons.</p>
                        </div>
                    </div>
                    
                    <div class="figure-item">
                        <img src="Pai_images/Figure_5.jpg" alt="Figure 5: Ex-vivo Tissue Results">
                        <div class="figure-caption">
                            <h3>Figure 5</h3>
                            <p>(a) Photograph of ex-vivo chicken tissue sample. (b-e) Reconstruction results: DAS, U-Net, HDU-Net, FAU-Net. (f) Quantitative comparison of FWHM, SNR, and CR. (g) Lateral profile of target.</p>
                        </div>
                    </div>
                    
                    <div class="figure-item">
                        <img src="Pai_images/Figure_6.jpg" alt="Figure 6: In-vivo Mouse Imaging">
                        <div class="figure-caption">
                            <h3>Figure 6</h3>
                            <p>Whole-body mouse imaging: MAP images reconstructed with U-Net, HDU-Net, and FAU-Net, with signal intensity profile comparison.</p>
                        </div>
                    </div>
                    
                    <div class="figure-item">
                        <img src="Pai_images/Figure_7.jpg" alt="Figure 7: PAM Simulations">
                        <div class="figure-caption">
                            <h3>Figure 7</h3>
                            <p>PAM simulated reconstructions with direct mapping, U-Net, HDU-Net, and FAU-Net.</p>
                        </div>
                    </div>
                    
                    <div class="figure-item">
                        <img src="Pai_images/Figure_8.jpg" alt="Figure 8: Goat Eye Imaging">
                        <div class="figure-caption">
                            <h3>Figure 8</h3>
                            <p>Projected MAP images from 3D goat-eye reconstructions using SAFT, SAFT+CF, and FAU-Net.</p>
                        </div>
                    </div>
                    
                    <div class="figure-item">
                        <img src="Pai_images/Figure_9.jpg" alt="Figure 9: Anatomical Layer Imaging">
                        <div class="figure-caption">
                            <h3>Figure 9</h3>
                            <p>Sectional MAP images of goat eye using SAFT, SAFT+CF, and FAU-Net across anatomical layers (outer tunic, middle tunic, inner tunic) with PA signal intensity plots.</p>
                        </div>
                    </div>
                    
                    <div class="figure-item">
                        <img src="Pai_images/Figure_10.jpg" alt="Figure 10: Phantom Study">
                        <div class="figure-caption">
                            <h3>Figure 10</h3>
                            <p>(a) Photograph of agar phantom with embedded human-hair targets. (b-e) Reconstructed 2D cross-sectional images: time-resolved, SAFT, SAFT+CF, FAU-Net. (iii-a,b) Line-plots for targets T1 and T14.</p>
                        </div>
                    </div>
                </div>

                <div class="references">
                    <h3>References</h3>
                    <ol>
                        <li>Rajendran P, Pramanik M. High frame rate (∼3 Hz) circular photoacoustic tomography using single-element ultrasound transducer aided with deep learning. J Biomed Opt. 2022 Jun;27(6):066005. doi: 10.1117/1.JBO.27.6.066005. Epub 2022 Jun 20. PMID: 36452448; PMCID: PMC9209813.</li>
                        <li>Davoudi, Neda & Dean-Ben, Xose Luis & Razansky, Daniel. (2019). Deep learning optoacoustic tomography with sparse data. Nature Machine Intelligence. 1. 1-8. 10.1038/s42256-019-0095-3.</li>
                    </ol>
                    
                    <p style="margin-top: 15px;"><strong>Data Citation:</strong> Davoudi (2019). Data. figshare. Dataset. <a href="https://doi.org/10.6084/m9.figshare.9250784.v1" target="_blank">https://doi.org/10.6084/m9.figshare.9250784.v1</a></p>
                </div>
            </div>
        </section>

        <div class="project-divider"></div>

        <!-- Project 2: Light Sheet Fluorescence Microscopy -->
        <section id="project2" class="project">
            <div class="project-header">
                <h2>Beyond the lens: Transforming light sheet fluorescence microscopy through stochastic elegance and iterative image refinement</h2>
            </div>
            <div class="project-content">
                <div class="authors">
                    <p>Tathagata Das<sup>1</sup>, Aiswarya K. S.<sup>1</sup>, Mayanglambam Suheshkumar Singh<sup>1,*</sup></p>
                    <p class="affiliations">
                        <sup>1</sup> Biomedical and Nano-bioscience Engineering Lab. (BnBEng.LAB), School of Physics (SoP), Indian Institute of Science Education and Research Thiruvananthapuram (IISER TVM), Kerala, India<br>
                        <sup>*</sup> Corresponding author: suhesh.kumar@iisertvm.ac.in
                    </p>
                </div>

                <div class="project-description">
                    <p>
                        This project enhanced the focus stability of a novel sMx-SPIM system, capable of capturing images at multiple magnifications. 
                        We applied deep learning techniques to maintain precise focus, even with challenging biological samples, ensuring clear and 
                        consistent imaging across different resolutions.
                    </p>
                </div>

                <div class="publication-info">
                    <h3>Publication Information</h3>
                    <p><strong>Title:</strong> Beyond the lens: Transforming light sheet fluorescence microscopy through stochastic elegance and iterative image refinement</p>
                    <p><strong>DOI:</strong> <a href="https://doi.org/10.1117/12.3044215" target="_blank" rel="noopener">10.1117/12.3044215</a></p>
                    <p><strong>Published in:</strong> SPIE Proceedings</p>
                    <p><strong>Abstract:</strong> This work presents a novel approach to light sheet fluorescence microscopy, combining stochastic methods with iterative image refinement techniques. The research demonstrates enhanced focus stability in a multi-magnification SPIM system (sMx-SPIM) through the application of deep learning methodologies, particularly focusing on maintaining precise focus across challenging biological samples and different imaging resolutions.</p>
                </div>

                <h3>Research Figures</h3>
                <div class="figures-container">
                    <div class="figure-item">
                        <div style="display: flex; flex-wrap: wrap; gap: 10px;">
                            <img src="lightsheetImages/figure1(a).png" alt="Figure 1(a)" style="flex: 1; min-width: 200px;">
                            <img src="lightsheetImages/figure1(b).jpg" alt="Figure 1(b)" style="flex: 1; min-width: 200px;">
                        </div>
                        <div class="figure-caption">
                            <h3>Figure 1</h3>
                            <p>Workflow of Diffusion based SR3 model</p>
                        </div>
                    </div>
                    
                    <div class="figure-item">
                        <img src="lightsheetImages/figure 2.png" alt="Figure 2" class="figure-image">
                        <div class="figure-caption">
                            <h3>Figure 2</h3>
                            <p>(a) Cell images captured at 10x magnificaton, (b) the corresponding images generated by the SR3 model using (a) as input, and (c) depict the ground truth images acquired at 20x magnification.</p>
                        </div>
                    </div>
                    
                    <div class="figure-item">
                        <img src="lightsheetImages/figure3.png" alt="Figure 3" class="figure-image">
                        <div class="figure-caption">
                            <h3>Figure 3</h3>
                            <p>A bar chart presenting the quantitative analysis of contrast ratio and signal-to-noise ratio (SNR) for images captured with an 11.11× lens, the SR3 model output, and a 22.22× lens.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <div class="project-divider"></div>

        <!-- Project 3: PMUT Photoacoustic Imaging -->
        <section id="project3" class="project">
            <div class="project-header">
                <h2>Deep Learning-Based Photoacoustic Image Reconstruction Using a Single-Element Low-Frequency PMUT</h2>
            </div>
            <div class="project-content">
                <div class="authors">
                    <p>Arijit Paramanick<sup>1</sup>, Kaustav Roy<sup>2</sup>, Deepayan Samanta<sup>1</sup>, Tathagata Das<sup>1</sup>, Rudra Pratap<sup>2</sup>, M suheshkumar singh<sup>1</sup></p>
                    <p class="affiliations">
                        <sup>1</sup> School of Physics, Indian Institute of Science and Research Thiruvananthapuram (IISER-TVM), Maruthamala, Vithura, Thiruvanthapuram, India, 695551.<br>
                        <sup>2</sup> Centre for Nano Science and Engineering, Indian Institute of Science, Bangalore, 560012
                    </p>
                </div>

                <div class="publication-info">
                    <p><strong>This work has been published in:</strong></p>
                    <p>SPIE Proceedings - Photons Plus Ultrasound: Imaging and Sensing 2025</p>
                    <p><strong>DOI:</strong> <a href="https://doi.org/10.1117/12.3043466" target="_blank">10.1117/12.3043466</a></p>
                    <p class="publication-note">Available at: <a href="https://doi.org/10.1117/12.3043466" target="_blank">https://doi.org/10.1117/12.3043466</a></p>
                </div>

                <div class="introduction">
                    <h3>Introduction</h3>
                    <ul>
                        <li>PA imaging technology provides signal or image contrast based on the optical absorption coefficient of the absorber.</li>
                        <li>PMUT, a MEMS-based ultrasound transducer, can replace conventional bulk ultrasound transducers; however, it suffers from lower sensitivity and generates significantly noisier data compared to traditional ultrasound transducers.</li>
                        <li>Here, we present a deep neural network method (modified U-Net), trained on simulated images, to address the challenges posed by significantly noisier PMUT signals, off-plane absorbers, and a limited number of scanning positions, with the aim of enhancing photoacoustic imaging (PAI) quality by improving spatial resolution, SNR, and CR.</li>
                        <li>The network's performance was validated using experimental results including tissue mimicking agar phantom and ex-vivo.</li>
                    </ul>
                </div>

                <h3>Research Figures</h3>
                <div class="figures-container">
                    <div class="figure-item">
                        <img src="arijt_spie_poster/page1_img3.jpeg" alt="PAI System">
                        <div class="figure-caption">
                            <h3>Figure 1</h3>
                            <p>The photoacoustic imaging (PAI) system: (i) The simulation setup used to generate the training data-set. (ii) The experimental setup to acquire the PA signals: (a) schematic diagram of the experimental PAI system, (b) a typical photograph of the home-built PMUT-setup.</p>
                        </div>
                    </div>

                    <div class="figure-item">
                        <img src="arijt_spie_poster/page1_img2.png" alt="Network Architecture">
                        <div class="figure-caption">
                            <h3>Figure 2</h3>
                            <p>Schematic diagram of the proposed network architecture</p>
                        </div>
                    </div>

                    <div class="figure-item">
                        <img src="arijt_spie_poster/page1_img1.jpeg" alt="Network Performance on Simulated Data">
                        <div class="figure-caption">
                            <h3>Figure 3</h3>
                            <p>Performance of the network on two types of simulated test datasets (disc-shaped and vasculature phantoms): (i-a, ii-a) images reconstructed using DAS (input to the CNN model), (i-b, ii-b) ground truth images, and (i-c, ii-c) predicted outputs.</p>
                        </div>
                    </div>

                    <div class="figure-item">
                        <img src="arijt_spie_poster/page1_img5.jpeg" alt="Network Performance on Agar Phantom">
                        <div class="figure-caption">
                            <h3>Figure 4</h3>
                            <p>Evaluation of the network's performance on experimental results using a tissue-mimicking agar phantom embedded with four pencil lead targets, separated by 1 mm along both the lateral and axial axes: (a) A typical photograph of the experimental phantom, (b) photoacoustic (PA) image reconstructed using the DAS algorithm (input to the CNN model), (c) image predicted by the network, and (d) lateral profile of the marked target (T) from the scanning surface.</p>
                        </div>
                    </div>

                    <div class="figure-item">
                        <img src="arijt_spie_poster/page1_img8.jpeg" alt="Network Performance on Ex-vivo">
                        <div class="figure-caption">
                            <h3>Figure 5</h3>
                            <p>Evaluation of the network's performance on a realistic photoacoustic (PA) specimen (ex-vivo): (a) photograph of the chicken tissue embedded with two graphite targets, (b) 3D volumetric image reconstructed using the DAS algorithm, and (c) 3D volumetric image reconstructed from the model's predicted output.</p>
                        </div>
                    </div>
                </div>

                <div class="references">
                    <h3>References</h3>
                    <ol>
                        <li>Dangi, Ajay, et al. "A photoacoustic imaging device using piezoelectric micromachined ultrasound transducers (PMUTs)." IEEE transactions on ultrasonics, ferroelectrics, and frequency control 67.4 (2019): 801-809.</li>
                        <li>Paramanick, Arijit, Deepayan Samanta, and Mayanglambam Suheshkumar Singh. "Non-zero data-filtering based photoacoustic image reconstruction: both for microscopy and tomography." IEEE Transactions on Instrumentation and Measurement (2025).</li>
                        <li>Liao, W., et al. "Piezeoelectric micromachined ultrasound tranducer array for photoacoustic imaging." 2013 Transducers & Eurosensors XXVII: The 17th International Conference on Solid-State Sensors, Actuators and Microsystems (TRANSDUCERS & EUROSENSORS XXVII). IEEE, 2013.</li>
                        <li>Paramanick, Arijit, et al. "Seeing Beyond: The Future of Photoacoustic Imaging with Single-element, Low-frequency Thin-film PMUT." IEEE Sensors Letters (2024).</li>
                    </ol>
                </div>
            </div>
        </section>
        </div>

        <footer>
            <div class="container">
                <p>&copy; 2024 - Research Projects</p>
            </div>
        </footer>
    </div><!-- End of main-wrapper -->
    
    <a href="#" class="back-to-top" id="backToTop">↑</a>

    <!-- Fireflies effect script with enhanced parallax using CSS 3D transforms -->
    <script src="fireflies.js"></script>
    <script>
        // Enhanced fireflies parallax effect using CSS 3D transforms
        document.addEventListener('DOMContentLoaded', function() {
            // Create a 3D perspective container for fireflies
            const fireflyContainer = document.getElementById('fireflies-container');
            
            if (fireflyContainer) {
                // Apply 3D perspective to the container
                fireflyContainer.style.perspective = '1000px';
                fireflyContainer.style.perspectiveOrigin = 'center center';
                fireflyContainer.style.transformStyle = 'preserve-3d';
                
                // Create three distinct layers for fireflies with different depths
                const layers = [
                    { z: -800, count: 10, speed: 0.01, size: [3, 5] },   // Deep background
                    { z: -400, count: 10, speed: 0.02, size: [4, 6] },   // Middle layer
                    { z: -100, count: 5, speed: 0.03, size: [5, 8] }     // Foreground
                ];
                
                // Create layered containers for each depth
                layers.forEach((layer, layerIndex) => {
                    // Create a layer container
                    const layerContainer = document.createElement('div');
                    layerContainer.className = 'firefly-layer';
                    layerContainer.style.position = 'absolute';
                    layerContainer.style.top = '0';
                    layerContainer.style.left = '0';
                    layerContainer.style.width = '100%';
                    layerContainer.style.height = '100%';
                    layerContainer.style.transformStyle = 'preserve-3d';
                    layerContainer.style.transform = `translateZ(${layer.z}px)`;
                    layerContainer.style.pointerEvents = 'none';
                    
                    // Scale the layer to compensate for the perspective
                    const scale = (1000 - layer.z) / 1000;
                    layerContainer.style.transform = `translateZ(${layer.z}px) scale(${scale})`;
                    
                    // Create fireflies for this layer
                    for (let i = 0; i < layer.count; i++) {
                        const firefly = document.createElement('div');
                        firefly.classList.add('firefly', 'parallax-firefly');
                        
                        // Randomize initial position
                        const x = Math.random() * 100;
                        const y = Math.random() * 100;
                        firefly.style.transform = `translate(${x}vw, ${y}vh)`;
                        
                        // Size based on layer
                        const minSize = layer.size[0];
                        const maxSize = layer.size[1];
                        const size = Math.random() * (maxSize - minSize) + minSize;
                        firefly.style.width = `${size}px`;
                        firefly.style.height = `${size}px`;
                        
                        // Adjust opacity based on layer (deeper = more transparent)
                        const opacity = 0.6 + (layerIndex * 0.2);
                        firefly.style.opacity = opacity;
                        
                        // Add to layer
                        layerContainer.appendChild(firefly);
                    }
                    
                    // Add layer to container
                    fireflyContainer.appendChild(layerContainer);
                });
                
                // Create a separate container for the original fireflies to keep them
                const originalFirefliesContainer = document.createElement('div');
                originalFirefliesContainer.className = 'original-fireflies';
                originalFirefliesContainer.style.position = 'absolute';
                originalFirefliesContainer.style.top = '0';
                originalFirefliesContainer.style.left = '0';
                originalFirefliesContainer.style.width = '100%';
                originalFirefliesContainer.style.height = '100%';
                originalFirefliesContainer.style.pointerEvents = 'none';
                
                // Move any existing fireflies to this container
                Array.from(fireflyContainer.querySelectorAll('.firefly:not(.parallax-firefly)')).forEach(firefly => {
                    originalFirefliesContainer.appendChild(firefly);
                });
                
                // Add the original fireflies container
                fireflyContainer.appendChild(originalFirefliesContainer);
                
                // Add animation to fireflies in each layer
                const allFireflies = document.querySelectorAll('.parallax-firefly');
                allFireflies.forEach(firefly => {
                    animateFirefly(firefly);
                });
                
                function animateFirefly(firefly) {
                    const duration = 5 + Math.random() * 10;
                    const startX = parseFloat(firefly.style.transform.split('(')[1].split('vw')[0]);
                    const startY = parseFloat(firefly.style.transform.split(', ')[1].split('vh')[0]);
                    
                    // Create a gentle random movement
                    const moveX = startX + (Math.random() * 10 - 5);
                    const moveY = startY + (Math.random() * 10 - 5);
                    
                    // Apply the animation
                    firefly.style.transition = `transform ${duration}s cubic-bezier(0.4, 0, 0.2, 1)`;
                    firefly.style.transform = `translate(${moveX}vw, ${moveY}vh)`;
                    
                    // Schedule next movement
                    setTimeout(() => {
                        animateFirefly(firefly);
                    }, duration * 1000);
                }
            }
        });
    </script>
    
    <script>
        // Back to top button functionality
        document.addEventListener('DOMContentLoaded', function() {
            const backToTopButton = document.getElementById('backToTop');
            
            // Show/hide back to top button based on scroll position
            window.addEventListener('scroll', function() {
                if (window.scrollY > 300) {
                    backToTopButton.classList.add('visible');
                } else {
                    backToTopButton.classList.remove('visible');
                }
            });
            
            // Smooth scroll to top when button is clicked
            backToTopButton.addEventListener('click', function(e) {
                e.preventDefault();
                window.scrollTo({
                    top: 0,
                    behavior: 'smooth'
                });
            });
            
            // Add animation to figure items with staggered delay
            const observer = new IntersectionObserver((entries) => {
                entries.forEach((entry, index) => {
                    if (entry.isIntersecting) {
                        setTimeout(() => {
                            entry.target.style.opacity = '1';
                            entry.target.style.transform = 'translateY(0)';
                        }, index * 100); // Staggered animation delay
                    }
                });
            }, {
                threshold: 0.1,
                rootMargin: '0px 0px -50px 0px'
            });

            document.querySelectorAll('.figure-item').forEach(item => {
                item.style.opacity = '0';
                item.style.transform = 'translateY(30px)';
                item.style.transition = 'opacity 0.8s ease, transform 0.8s ease';
                observer.observe(item);
            });
            
            // Add animation to project sections
            const projectObserver = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('project-visible');
                    }
                });
            }, {
                threshold: 0.1,
                rootMargin: '0px 0px -100px 0px'
            });
            
            document.querySelectorAll('.project').forEach(project => {
                projectObserver.observe(project);
            });
            
            // Enhanced parallax effects
            window.addEventListener('scroll', function() {
                const scrollPosition = window.scrollY;
                const header = document.querySelector('header');
                const projects = document.querySelectorAll('.project');
                const figures = document.querySelectorAll('.figure-item');
                const toc = document.querySelector('.table-of-contents');
                
                // Parallax header - faster movement for foreground
                if (scrollPosition < 800) {
                    header.style.backgroundPosition = `center ${scrollPosition * 0.6}px`;
                    header.style.transform = `translateY(${scrollPosition * 0.3}px)`;
                }
                
                // Parallax for projects - increased movement for foreground
                projects.forEach((project, index) => {
                    const projectPosition = project.getBoundingClientRect().top;
                    const windowHeight = window.innerHeight;
                    
                    if (projectPosition < windowHeight * 0.9 && projectPosition > -windowHeight * 0.5) {
                        const parallaxOffset = (projectPosition - windowHeight * 0.5) * 0.08;
                        project.style.transform = `translateY(${parallaxOffset}px)`;
                    }
                });
                
                // Enhanced parallax for figure items - more pronounced movement
                figures.forEach((figure) => {
                    const figurePosition = figure.getBoundingClientRect().top;
                    const windowHeight = window.innerHeight;
                    
                    if (figurePosition < windowHeight * 1.1 && figurePosition > -windowHeight * 0.2) {
                        const parallaxOffset = (figurePosition - windowHeight * 0.5) * 0.05;
                        figure.style.transform = `translateY(${-parallaxOffset}px)`;
                    }
                });
                
                // Table of contents parallax
                if (toc) {
                    const tocPosition = toc.getBoundingClientRect().top;
                    if (tocPosition < window.innerHeight && tocPosition > -toc.offsetHeight) {
                        toc.style.transform = `translateY(${scrollPosition * 0.02}px)`;
                    }
                }
            });
            
            // Add hover effect to figure images
            document.querySelectorAll('.figure-item').forEach(item => {
                const img = item.querySelector('img');
                
                if (img) {
                    item.addEventListener('mouseenter', () => {
                        img.style.transform = 'scale(1.03)';
                        img.style.transition = 'transform 0.5s ease';
                    });
                    
                    item.addEventListener('mouseleave', () => {
                        img.style.transform = 'scale(1)';
                    });
                }
            });
            
            // Smooth scroll for table of contents links
            document.querySelectorAll('.table-of-contents a').forEach(link => {
                link.addEventListener('click', function(e) {
                    e.preventDefault();
                    
                    const targetId = this.getAttribute('href').substring(1);
                    const targetElement = document.getElementById(targetId);
                    
                    if (targetElement) {
                        window.scrollTo({
                            top: targetElement.offsetTop - 100,
                            behavior: 'smooth'
                        });
                    }
                });
            });
        });
    </script>
</body>
</html> 